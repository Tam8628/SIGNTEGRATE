{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6073a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "# import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage.interpolation as inter\n",
    "from scipy.signal import medfilt \n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from keras.layers.convolutional import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcbdce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 20 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_num = 20 # the number of class\n",
    "        self.feat_d = 190\n",
    "        self.filters = 64\n",
    "        self.nd = 60\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "148fd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(p,target_l=32,joints_num=20,joints_dim=3):\n",
    "    l = p.shape[0]\n",
    "    p_new = np.empty([target_l,joints_num,joints_dim]) \n",
    "    for m in range(joints_num):\n",
    "        for n in range(joints_dim):\n",
    "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
    "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]         \n",
    "    return p_new\n",
    "\n",
    "def sampling_frame(p,C):\n",
    "    full_l = p.shape[0] # full length\n",
    "    if random.uniform(0,1)<0.5: # aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        s = random.randint(0, full_l-int(valid_l))\n",
    "        e = s+valid_l # sample end point\n",
    "        p = p[int(s):int(e),:,:]    \n",
    "    else: # without aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
    "        p = p[index,:,:]\n",
    "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
    "    return p\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "def get_CG(p,C):\n",
    "    M = []\n",
    "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
    "    for f in range(C.frame_l):\n",
    "        #distance max \n",
    "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')       \n",
    "        d_m = d_m[iu] \n",
    "        M.append(d_m)\n",
    "    M = np.stack(M)   \n",
    "    return M\n",
    "\n",
    "def norm_train(p):\n",
    "    # normolize to start point, use the center for hand case\n",
    "    # p[:,:,0] = p[:,:,0]-p[:,3:4,0]\n",
    "    # p[:,:,1] = p[:,:,1]-p[:,3:4,1]\n",
    "    # p[:,:,2] = p[:,:,2]-p[:,3:4,2]\n",
    "    # # return p\n",
    "       \n",
    "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "    return p\n",
    "def norm_train2d(p):\n",
    "    # normolize to start point, use the center for hand case\n",
    "    # p[:,:,0] = p[:,:,0]-p[:,3:4,0]\n",
    "    # p[:,:,1] = p[:,:,1]-p[:,3:4,1]\n",
    "    # p[:,:,2] = p[:,:,2]-p[:,3:4,2]\n",
    "    # # return p\n",
    "       \n",
    "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "    # p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "    return p\n",
    "# def normlize_test(p):\n",
    "#     # normolize to start point, use the center for hand case\n",
    "#     p[:,:,0] = p[:,:,0]-p[:,1:2,0]\n",
    "#     p[:,:,1] = p[:,:,1]-p[:,1:2,1]\n",
    "#     p[:,:,2] = p[:,:,2]-p[:,1:2,2]\n",
    "#     # p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "#     # p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "#     # p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "#     return p\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4970725",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rate = 0.1\n",
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize(x,size=[H,W]) \n",
    "    return x\n",
    "def poses_diff_2(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    # x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize(x,size=[H,W]) \n",
    "    return x\n",
    "def pose_motion_2(D, frame_l):\n",
    "    x_1 = Lambda(lambda x: poses_diff_2(x))(D)\n",
    "    x_1 = Reshape((frame_l,-1))(x_1)\n",
    "    return x_1\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
    "    x_1 = Reshape((frame_l,-1))(P)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "# def reshape_x_2(D, frame_l):\n",
    "#     x_1 = Lambda(lambda y: poses_diff_2(y))(D)\n",
    "#     x_1 = Reshape((frame_l, -1))(D)\n",
    "\n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=20,joint_d=3,feat_d=190,filters=16, nd=60):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    # D = Input(shape =(frame_l, joint_n, joint_d))\n",
    "    # x_ = pose_motion_2(D, frame_l)\n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "    \n",
    "\n",
    "\n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    \n",
    "    # x_1 = c1D(x_1, filters*2,1)\n",
    "    # x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "    # x_1 = c1D(x_1, filters, 3)\n",
    "    # x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "    # x_1 = c1D(x_1, filters,1)\n",
    "    # x_1 = MaxPooling1D(2)(x_1)\n",
    "    # x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "\n",
    "    # x = c1D(diff_fast,filters*2,1)\n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,3) \n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,1) \n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)\n",
    "\n",
    "\n",
    "def build_DD_Net(C):\n",
    "    M = Input(name='M', shape=(C.frame_l,C.feat_d))  \n",
    "    P = Input(name='P', shape=(C.frame_l,C.joint_n,C.joint_d)) \n",
    "    # D = Input(name ='D', shape =(C.frame_l, C.joint_n,C.joint_d))\n",
    "    FM = build_FM(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(20, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9191adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Train = pickle.load(open(\"train-MSRAfull.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(\"test-MSRAfull.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5aaf841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  [(None, 32, 190)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  [(None, 32, 20, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 4, 512)       1733376     M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 512)          0           model_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          65536       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128)          512         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 128)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          16384       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 128)          0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20)           2580        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,818,900\n",
      "Trainable params: 1,813,268\n",
      "Non-trainable params: 5,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C)\n",
    "DD_Net.summary()\n",
    "\n",
    "DD_Net.load_weights('msr-full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb56deb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 284/284 [00:02<00:00, 141.15it/s]\n"
     ]
    }
   ],
   "source": [
    "X_1 =[]\n",
    "X_0 =[]\n",
    "Y =[]\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,20,3])\n",
    " \n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    \n",
    "    # X_2.append(x_)\n",
    "    p = norm_train(p)\n",
    "    M = get_CG(p,C)\n",
    "   \n",
    "    X_0.append(M)\n",
    "    # p = norm_train2d(p)\n",
    "    X_1.append(p)\n",
    "    \n",
    "# for i in tqdm(range(len(y_train))): \n",
    "    \n",
    "    label = np.zeros(20)\n",
    "    label[Train['label'][i]-1] = 1   \n",
    "    # label[Train_1['label'][i]] = 1\n",
    "\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "# X_2 = np.stack(X_2) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a08da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 283/283 [00:01<00:00, 143.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "# X_test_2 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,20,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = norm_train(p)\n",
    "    # X_test_2.append(x_)\n",
    "    M = get_CG(p,C)\n",
    "    X_test_0.append(M)\n",
    "    # p = norm_train2d(p)\n",
    "    X_test_1.append(p)\n",
    "\n",
    "# for i in tqdm(range(len(y_test))):    \n",
    "    label = np.zeros(20)\n",
    "    label[Test['label'][i]-1] = 1   \n",
    "    # label[le.transform(Test['label'])[i]] = 1   \n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1) \n",
    "# X_test_2 = np.stack(X_test_2)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc561dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 296 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.1901278e-01, 4.3546259e-03, 1.1197896e-03, ..., 2.4988432e-03,\n",
       "        4.6630856e-03, 8.7476347e-04],\n",
       "       [1.8763350e-02, 4.3924125e-03, 1.0850975e-02, ..., 1.0427498e-01,\n",
       "        2.0046495e-02, 9.5603261e-03],\n",
       "       [9.8102552e-01, 1.1803084e-03, 1.3193022e-04, ..., 4.6765321e-04,\n",
       "        8.4972644e-04, 3.6899225e-04],\n",
       "       ...,\n",
       "       [2.2094119e-04, 9.4077346e-04, 5.8280741e-04, ..., 8.5396208e-03,\n",
       "        1.5819821e-03, 9.7802907e-01],\n",
       "       [8.9630258e-04, 1.1736358e-03, 3.3459577e-04, ..., 4.7978181e-03,\n",
       "        2.0080572e-03, 9.7634965e-01],\n",
       "       [1.1246058e-02, 1.1092593e-02, 1.4209203e-02, ..., 2.0558046e-02,\n",
       "        6.1133686e-02, 4.5707768e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DD_Net.predict([X_test_0, X_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa38aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
