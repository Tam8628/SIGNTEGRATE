{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf9fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "# import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage.interpolation as inter\n",
    "from scipy.signal import medfilt \n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from keras.layers.convolutional import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2a80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 96 # the length of frames\n",
    "        self.joint_n = 33 # the number of joints\n",
    "        self.joint_d = 2 # the dimension of joints\n",
    "        self.clc_num = 10 # the number of class\n",
    "        self.feat_d = 528\n",
    "        self.filters = 64\n",
    "        self.nd = 60\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e609e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(p,target_l=32,joints_num=20,joints_dim=3):\n",
    "    l = p.shape[0]\n",
    "    p_new = np.empty([target_l,joints_num,joints_dim]) \n",
    "    for m in range(joints_num):\n",
    "        for n in range(joints_dim):\n",
    "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
    "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]         \n",
    "    return p_new\n",
    "\n",
    "def sampling_frame(p,C):\n",
    "    full_l = p.shape[0] # full length\n",
    "    if random.uniform(0,1)<0.5: # aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        s = random.randint(0, full_l-int(valid_l))\n",
    "        e = s+valid_l # sample end point\n",
    "        p = p[int(s):int(e),:,:]    \n",
    "    else: # without aligment sampling\n",
    "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
    "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
    "        p = p[index,:,:]\n",
    "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
    "    return p\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "def get_CG(p,C):\n",
    "    M = []\n",
    "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
    "    for f in range(C.frame_l):\n",
    "        #distance max \n",
    "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')       \n",
    "        d_m = d_m[iu] \n",
    "        M.append(d_m)\n",
    "    M = np.stack(M)   \n",
    "    return M\n",
    "\n",
    "def norm_train(p):\n",
    "    # normolize to start point, use the center for hand case\n",
    "    # p[:,:,0] = p[:,:,0]-p[:,3:4,0]\n",
    "    # p[:,:,1] = p[:,:,1]-p[:,3:4,1]\n",
    "    # p[:,:,2] = p[:,:,2]-p[:,3:4,2]\n",
    "    # # return p\n",
    "       \n",
    "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "    return p\n",
    "def norm_train2d(p):\n",
    "    # normolize to start point, use the center for hand case\n",
    "    # p[:,:,0] = p[:,:,0]-p[:,3:4,0]\n",
    "    # p[:,:,1] = p[:,:,1]-p[:,3:4,1]\n",
    "    # p[:,:,2] = p[:,:,2]-p[:,3:4,2]\n",
    "    # # return p\n",
    "       \n",
    "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "    # p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "    return p\n",
    "# def normlize_test(p):\n",
    "#     # normolize to start point, use the center for hand case\n",
    "#     p[:,:,0] = p[:,:,0]-p[:,1:2,0]\n",
    "#     p[:,:,1] = p[:,:,1]-p[:,1:2,1]\n",
    "#     p[:,:,2] = p[:,:,2]-p[:,1:2,2]\n",
    "#     # p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
    "#     # p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
    "#     # p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
    "#     return p\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c52b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rate = 0.1\n",
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize(x,size=[H,W]) \n",
    "    return x\n",
    "def poses_diff_2(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    # x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize(x,size=[H,W]) \n",
    "    return x\n",
    "def pose_motion_2(D, frame_l):\n",
    "    x_1 = Lambda(lambda x: poses_diff_2(x))(D)\n",
    "    x_1 = Reshape((frame_l,-1))(x_1)\n",
    "    return x_1\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
    "    x_1 = Reshape((frame_l,-1))(P)\n",
    "    return P_diff_slow,P_diff_fast, x_1\n",
    "# def reshape_x_2(D, frame_l):\n",
    "#     x_1 = Lambda(lambda y: poses_diff_2(y))(D)\n",
    "#     x_1 = Reshape((frame_l, -1))(D)\n",
    "\n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=20,joint_d=3,feat_d=190,filters=16, nd=60):   \n",
    "    # M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    # D = Input(shape =(frame_l, joint_n, joint_d))\n",
    "    # x_ = pose_motion_2(D, frame_l)\n",
    "    diff_slow,diff_fast, x_1 = pose_motion(P,frame_l)\n",
    "    \n",
    "\n",
    "\n",
    "    # x = c1D(P,filters*2,1)\n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,3)\n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,1)\n",
    "    # x = MaxPooling1D(2)(x)\n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    \n",
    "    x_1 = c1D(x_1, filters*2,1)\n",
    "    x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "    x_1 = c1D(x_1, filters, 3)\n",
    "    x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "    x_1 = c1D(x_1, filters,1)\n",
    "    x_1 = MaxPooling1D(2)(x_1)\n",
    "    x_1 = SpatialDropout1D(drop_rate)(x_1)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(drop_rate)(x_d_slow)\n",
    "\n",
    "    # x = c1D(diff_fast,filters*2,1)\n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,3) \n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "    # x = c1D(x,filters,1) \n",
    "    # x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(drop_rate)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x_1,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(drop_rate)(x)\n",
    "    \n",
    "    return Model(inputs=[P],outputs=x)\n",
    "\n",
    "\n",
    "def build_DD_Net(C):\n",
    "    # M = Input(name='M', shape=(C.frame_l,C.feat_d))  \n",
    "    P = Input(name='P', shape=(C.frame_l,C.joint_n,C.joint_d)) \n",
    "    # D = Input(name ='D', shape =(C.frame_l, C.joint_n,C.joint_d))\n",
    "    FM = build_FM(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.filters)\n",
    "    \n",
    "    x = FM([P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9b6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_rt(T):\n",
    "    X = []\n",
    "#     X_1 = []\n",
    "\n",
    "    T = np.expand_dims(T, axis = 0)\n",
    "    for i in range(len(T)): \n",
    "        p = T[i]\n",
    "#         p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "\n",
    "#         M = get_CG(p,C)\n",
    "\n",
    "#         X_0.append(M)\n",
    "#         p = norm_train2d(p)\n",
    "\n",
    "        X.append(p)\n",
    "\n",
    "    X = np.stack(X)  \n",
    "#     X_1 = np.stack(X_1) \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5897b9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_text = ['Xin chào, rất vui được gặp bạn!', 'Tạm biệt, hẹn gặp lại!', 'Xin cảm ơn, bạn thật tốt bụng!', 'Tôi xin lỗi, bạn có sao không','Tôi yêu gia đình và bạn bè.', 'Tôi là học sinh.', 'Tôi thích động vật.', 'Tôi ăn cơm.', 'Tôi sống ở Việt Nam.','Tôi là người Điếc']\n",
    "# labels = ['1', '2','3','4','5','6','7','8','9','10']\n",
    "labels = ['xin chao rat vui duoc gap ban', 'tam biet hen gap lai', 'xin cam on ban that tot bung', 'toi xin loi ban co sao khong', 'toi yeu gia dinh va ban be', 'toi la hoc sinh', 'toi thich dong vat', 'toi an com', 'toi song o viet nam', 'toi la nguoi diec']\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638fafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "#         cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)  \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e6f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6dc450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "P (InputLayer)               [(None, 96, 33, 2)]       0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 12, 512)           1719040   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,803,274\n",
      "Trainable params: 1,797,642\n",
      "Non-trainable params: 5,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C)\n",
    "DD_Net.summary()\n",
    "\n",
    "DD_Net.load_weights('nnkh-8-11-cv(1).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5758d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin chào, rất vui được gặp bạn!\n",
      "['', 'xin chao rat vui duoc gap ban']\n",
      "Tôi là học sinh.\n",
      "['', 'xin chao rat vui duoc gap ban', 'toi la hoc sinh']\n",
      "Tôi là học sinh.\n",
      "['', 'xin chao rat vui duoc gap ban', 'toi la hoc sinh', 'toi la hoc sinh']\n",
      "Tôi là người Điếc\n",
      "['', 'xin chao rat vui duoc gap ban', 'toi la hoc sinh', 'toi la hoc sinh', 'toi la nguoi diec']\n",
      "Tôi là học sinh.\n",
      "['', 'xin chao rat vui duoc gap ban', 'toi la hoc sinh', 'toi la hoc sinh', 'toi la nguoi diec', 'toi la hoc sinh']\n"
     ]
    }
   ],
   "source": [
    "time0 = 0\n",
    "sequence = []\n",
    "sentence = ['']\n",
    "predictions = []\n",
    "threshold = 0.6\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Draw the pose annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "            )\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            keypoint = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark]).flatten()\n",
    "            keypoint = np.array_split(keypoint, 33)\n",
    "            #print(keypoint)\n",
    "            sequence.append(keypoint)\n",
    "            #print(sequence)\n",
    "            sequence = sequence[-116:]\n",
    "\n",
    "        if len(sequence) == 116:\n",
    "            #print(sequence)\n",
    "            X_test_rt = data_generator_rt(sequence[-96:])\n",
    "            res = DD_Net.predict([X_test_rt])[0]\n",
    "            print(labels_text[np.argmax(res)])\n",
    "            sentence.append(labels[np.argmax(res)])\n",
    "#             predictions.append(np.argmax(res))\n",
    "#             sequence.clear()\n",
    "#             if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "#                 if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "#                     if len(sentence) > 0: \n",
    "#                         if labels[np.argmax(res)] != sentence[-1]:\n",
    "#                             sentence.append(labels[np.argmax(res)])\n",
    "#                     else:\n",
    "#                         sentence.append(labels[np.argmax(res)])\n",
    "            sequence.clear()  \n",
    "#             if len(sentence) > 1: \n",
    "#                 sentence = sentence[-1:]\n",
    "            print(sentence)\n",
    "#             image = prob_viz(res, labels, image, colors)\n",
    "\n",
    "        # Show fps\n",
    "        time1 = time.time()\n",
    "        fps = 1 / (time1 - time0)\n",
    "        time0 = time1\n",
    "        cv2.putText(image,'FPS:' + str(int(fps)), (3, 475), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "#         cv2.putText(image, ' '.join(sentence), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, ''.join(sentence[-1:]), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29917232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8e570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b82dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
